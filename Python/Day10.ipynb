{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html문서를 가지고 왔다고 생각했을때\n",
    "html = '''\n",
    "<html><body>\n",
    "<h1>스크래핑</h1>\n",
    "<p>웹 페이지 분석</p>\n",
    "<p>원하는 부분 추출</p>\n",
    "</body></html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser') # BeautifulSoup(html문서, html 분석기 종류)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<html><body>\n",
       "<h1>스크래핑</h1>\n",
       "<p>웹 페이지 분석</p>\n",
       "<p>원하는 부분 추출</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body>\n",
       "<h1>스크래핑</h1>\n",
       "<p>웹 페이지 분석</p>\n",
       "<p>원하는 부분 추출</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<h1>스크래핑</h1>\n",
       "<p>웹 페이지 분석</p>\n",
       "<p>원하는 부분 추출</p>\n",
       "</body>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = soup.html.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = soup.html.body.p #가장 처음으로 만나는 p태그\n",
    "# p태크 : 형제태그\n",
    "\n",
    "p1.next_sibling #<p>웹 페이지 분석</p>옆에 있는 엔터가 참조됨 => next_sibling을 두번 해주어야함\n",
    "p2 = p1.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크래핑\n",
      "웹 페이지 분석\n",
      "원하는 부분 추출\n"
     ]
    }
   ],
   "source": [
    "# 태크에 묶어서 나오는데 문자열만 출력을 원할때 .string\n",
    "print(h1.string)\n",
    "print(p1.string)\n",
    "print(p2.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find함수 : id를 이용하여 직접 접근\n",
    "\n",
    "\n",
    "html = '''\n",
    "<html><body>\n",
    "<h1 id = \"title\">스크래핑</h1>\n",
    "<p id = \"body\">웹 페이지 분석</p>\n",
    "<p>원하는 부분 추출</p>\n",
    "</body></html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser') # BeautifulSoup(html문서, html 분석기 종류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title= 스크래핑\n",
      "body= 웹 페이지 분석\n"
     ]
    }
   ],
   "source": [
    "title = soup.find(id=\"title\")\n",
    "body = soup.find(id=\"body\")\n",
    "\n",
    "print(\"title= \"+title.string)\n",
    "print(\"body= \"+body.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html><body>\n",
    "<ul> #ul: 순서 없음 ol : 순서있음\n",
    "<li><a href = \"http://www.naver.com\">naver</a></li> # a태그 : 눌렀을떄 네이버로 앵커태그\n",
    "<li><a href = \"http://www.daum.net\">daum</a></li> #href : 속성 href = 속성값\n",
    "</ul>\n",
    "</body></html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all() : 여러개의 태그를 한번에 추출\n",
    "links = soup.find_all(\"a\") # 리스트로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver -> http://www.naver.com\n",
      "daum -> http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "for a in links:\n",
    "#     if 'href' in a.attrs:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text,\"->\",href)\n",
    "#     print(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상청 기상예보에서 특정 내용 추출\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'기압골의 영향으로 6일부터 8일 사이에 전국에 비 또는 눈이 오겠고, 제주도는 10~11일에도 비가 오겠습니다. <br />한편, 동풍의 영향으로 9일은 강원영동에 비 또는 눈이 오겠습니다. 그 밖의 날은 고기압의 가장자리에 들어 가끔 구름많겠습니다.<br />기온은 평년(최저기온: -12~0℃, 최고기온: 0~8℃)보다 높겠습니다.<br />강수량은 평년(0~3mm)보다 많겠습니다.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,\"html.parser\")\n",
    "\n",
    "# title 검색\n",
    "soup.title.string # 유일하다면 다이렉트로 들어가도 됨\n",
    "soup.find(\"title\").string\n",
    "\n",
    "# wf태그값 추출\n",
    "soup.find(\"wf\").string\n",
    "\n",
    "#영문,숫자 등 특수 문자 모두제거(한글제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# css 선택자(크롬->개발자도구->개체선택->copy selector) 사용하기\n",
    "# soup.select_one(선택자) : 선택자로 지정된 요소 하나를 추출\n",
    "# soup.select(선택자) : 선택자로 지정된 여러 개 요소를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div id='myid'>\n",
    "            <h1>2020년</h1>\n",
    "            <ul class = 'day'>\n",
    "                <li>월요일</li>\n",
    "                <li>화요일</li>\n",
    "                <li>수요일</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020년'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')\n",
    "soup.select_one(\"div#myid h1\")\n",
    "soup.select_one(\"div#myid > h1\").string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li>월요일</li>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select_one(\"div#myid ul.day li\") # class는 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월요일\n",
      "화요일\n",
      "수요일\n"
     ]
    }
   ],
   "source": [
    "myList = soup.select(\"div#myid ul.day li\") #리스트로 나오기때문에 바로 string으로 바꿀 수 없음\n",
    "\n",
    "for a in myList:\n",
    "    print(a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55,500.00'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://finance.yahoo.com/quote/005930.KS?p=005930.KS&.tsrc=fin-srch\"\n",
    "\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,\"html.parser\")\n",
    "\n",
    "soup.select_one(\"#quote-header-info > div.My(6px).Pos(r).smartphone_Mt(6px) > div > span\").string\n",
    "\n",
    "# quote-header-info > div.My(6px).Pos(r).smartphone_Mt(6px) > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"My(6px) Pos(r) smartphone_Mt(6px)\" data-reactid=\"12\"><div class=\"\" data-reactid=\"13\"><span class=\"Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)\" data-reactid=\"14\">55,500.00</span><div class=\"D(ib) Va(t) \" data-reactid=\"15\"><span class=\"Trsdu(0.3s) Fw(500) Fz(14px) C($dataRed)\" data-reactid=\"16\">-300.00 (-0.54%)</span><div class=\"Fw(n) C($tertiaryColor) Fz(12px) Mstart(10px) D(ib) Mstart(0)--mobpsm Mt(6px)--mobpsm\" data-reactid=\"17\" id=\"quote-market-notice\"><span data-reactid=\"18\">As of  11:34AM KST. Market open.</span></div></div></div></div>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = soup.select(\"#quote-header-info > div\")[2]\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서시\n",
      "자화상\n",
      "소년\n",
      "눈 오는 지도\n",
      "돌아와 보는 밤\n",
      "병원\n",
      "새로운 길\n",
      "간판 없는 거리\n",
      "태초의 아침\n",
      "또 태초의 아침\n",
      "새벽이 올 때까지\n",
      "무서운 시간\n",
      "십자가\n",
      "바람이 불어\n",
      "슬픈 족속\n",
      "눈감고 간다\n",
      "또 다른 고향\n",
      "길\n",
      "별 헤는 밤\n"
     ]
    }
   ],
   "source": [
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,\"html.parser\")\n",
    "a = soup.select(\"#mw-content-text > div > ul > li > ul > li\")\n",
    "\n",
    "for i in a:\n",
    "    print(i.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서시\n",
      "자화상\n",
      "소년\n",
      "눈 오는 지도\n",
      "돌아와 보는 밤\n",
      "병원\n",
      "새로운 길\n",
      "간판 없는 거리\n",
      "태초의 아침\n",
      "또 태초의 아침\n",
      "새벽이 올 때까지\n",
      "무서운 시간\n",
      "십자가\n",
      "바람이 불어\n",
      "슬픈 족속\n",
      "눈감고 간다\n",
      "또 다른 고향\n",
      "길\n",
      "별 헤는 밤\n"
     ]
    }
   ],
   "source": [
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,\"html.parser\")\n",
    "a = soup.select_one(\"#mw-content-text > div > ul > li > ul\").text\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "Python\n",
      "Python\n",
      "Python\n",
      "Python\n",
      "Python\n",
      "Python\n",
      "Python\n",
      "Python\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<ul id='language'>\n",
    "<li id = \"bas\">Basic</li>\n",
    "<li id = \"cpp\">c++</li>\n",
    "<li id = \"ja\">Java</li>\n",
    "<li id = \"py\">Python</li>\n",
    "<li id = \"sp\">Spark</li>\n",
    "</ul>\n",
    "'''\n",
    "\n",
    "sel = BeautifulSoup(html,\"html.parser\")\n",
    "sel.select_one(\"#py\")\n",
    "\n",
    "myFunc = lambda arg :print(sel.select_one(arg).string)\n",
    "myFunc(\"#py\")\n",
    "myFunc('li#py')\n",
    "myFunc(\"ul > li#py\")\n",
    "myFunc(\"#language #py\")\n",
    "myFunc(\"#language > #py\")\n",
    "myFunc(\"ul#language > li#py\")\n",
    "myFunc(\"li[id='py']\")\n",
    "myFunc(\"li:nth-of-type(4)\")\n",
    "print(sel.select(\"li\")[3].string)\n",
    "print(sel.find_all('li')[3].string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fru-veg.html 파일 읽기\n",
    "fp = open(\"fru-veg.html\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<title>Title</title>\n",
       "</head>\n",
       "<body>\n",
       "<div id=\"main-goods\" role=\"page\">\n",
       "<h1>과일과 야채</h1>\n",
       "<ul id=\"fr\">\n",
       "<li class=\"red green\" data-lo=\"ko\">사과</li>\n",
       "<li class=\"purple\" data-lo=\"ko\">포도</li>\n",
       "<li class=\"yellow\" data-lo=\"ko\">레몬</li>\n",
       "<li class=\"yellow\" data-lo=\"ko\">오렌지</li>\n",
       "</ul>\n",
       "<ul id=\"ve\">\n",
       "<li class=\"white green\" data-lo=\"ko\">무</li>\n",
       "<li class=\"red green\" data-lo=\"us\">파프리카</li>\n",
       "<li class=\"black\" data-lo=\"ko\">가지</li>\n",
       "<li class=\"black\" data-lo=\"us\">아보카도</li>\n",
       "<li class=\"white\" data-lo=\"cn\">연근</li>\n",
       "</ul>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(fp,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n"
     ]
    }
   ],
   "source": [
    "# 아보카도 추출\n",
    "print(soup.select_one(\"li:nth-of-type(8)\").string)\n",
    "print(soup.select_one(\"ul#ve > li:nth-of-type(4)\").string)\n",
    "print(soup.select(\"#ve li[data-lo='us']\")[1].string) #ve -> data-lo=\"us\" 중 2번째\n",
    "print(soup.select('#ve li.black')[1].string)\n",
    "\n",
    "#find 매서드\n",
    "cond = {'data-lo':'us','class':'black'}\n",
    "cond2 = {'class':'black','data-lo':'us'}\n",
    "print(soup.find(\"li\",cond2).string)\n",
    "\n",
    "print(soup.find(id='ve').find(\"li\",cond).string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://test.html\">test2</a>,\n",
       " <a href=\"https://test.html\">test3</a>,\n",
       " <a href=\"https://test.html\">test4</a>]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식과 함꼐 데이터 추출\n",
    "html='''\n",
    "<li><a href=\"test.html\">test</li>\n",
    "<li><a href=\"https://test.html\">test2</li>\n",
    "<li><a href=\"https://test.html\">test3</li>\n",
    "<li><a href=\"https://test.html\">test4</li>\n",
    "'''\n",
    "import re\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "li = soup.find_all(href=re.compile('https://'))\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
